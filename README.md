# Implementing_SLAM
This is a self-learned project that leads to the first step in understanding and analyzing the performance of self-driven robots and cars using Reinforcement learning. Simultaneous Localization And Mapping or SLAM is the most common way that helps the agent predict and learn from its surroundings, to take the steps in its journey towards goal. This is basically implemented using different kinds of sensors and actuators such as LIDAR , gyro and so on, in the state of the art models. Being a fan of AI and its application and a student who takes his first step towards Deep learning and Neural networks, I'm trying to implement it using Python code in way that mimics SLAM. This basically does with two steps : 1. Maps the surroundings or room to create an idea about the area which it is in.   2.  Creating a co-ordinate system with the area and localizing itself within the map, using the information that it got from the surrounding during mapping (Step 1).
After the study on mpu6050 (Accelerometer+Gyroscope) and MEMS and IMU in general, the I2C communication was developed between raspberry pi and the sensor. Used in-built python library for mpu6050 to obtain values of in all the three axes. 
Research on Sensor Fusion algorithm ended up in Complementry filter (used a HPF and LPF) to combine the gyro and accelerometer values.
A 2D- mapping of the robot involves the movement in the x-y plane defined by the position (x,y), velocities(vx,vy) and yaw(angle wrt z-axis) giving the orientation.
........................................................................UPDATES COMING SOON....................................................................![1622740098290](https://user-images.githubusercontent.com/61682876/121820133-2711ff00-cce5-11eb-8e3e-27f414f44afa.jpg)
![1622885024387](https://user-images.githubusercontent.com/61682876/121820134-28432c00-cce5-11eb-9474-b1e79aa9330f.jpg)
